---
title: "CT"
author: "Jens Daniel Müller & Lara Burchardt"
date:  "`r format(Sys.time(), '%d %B, %Y')`"
output: 
  workflowr::wflow_html:
    number_sections: true
    toc_depth: 3
    toc_float:
      collapsed: false
editor_options:
  chunk_output_type: console
---


```{r global_options, include = FALSE}
knitr::opts_chunk$set(warning=FALSE, message=FALSE)
```

```{r library, message=FALSE, warning=FALSE}

library(tidyverse)
library(ncdf4)
library(vroom)
library(lubridate)
library(geosphere)
library(dygraphs)
library(xts)
library(here)
library(seacarb)
library(zoo)
library(RColorBrewer)

```


```{r ggplot_theme, include = FALSE}
theme_set(theme_bw())
```


```{r subsetting_criteria}

# route
select_route <- c("E", "F", "G", "W", "X") 

# variable names in 2d and 3d GETM files
var <- "SSS_east"

# latitude limits
low_lat <- 58.5
high_lat <- 59.0

```

# Regional mean salinity

The mean salinity was calculated across all measurments made between march - september in the NGS subregion. 


```{r read_sss_data_fm_ngs}

nc <- nc_open(paste("data/Finnmaid/", "FM_all_2019_on_standard_tracks.nc", sep = ""))

# read required vectors from netcdf file
route <- ncvar_get(nc, "route")
route <- unlist(strsplit(route, ""))
date_time <- ncvar_get(nc, "time")
latitude_east <- ncvar_get(nc, "latitude_east")

array <- ncvar_get(nc, var) # store the data in a 2-dimensional array
#dim(array) # should have 2 dimensions: 544 coordinate, 2089 time steps
  
  fillvalue <- ncatt_get(nc, var, "_FillValue")
  array[array == fillvalue$value] <- NA
  rm(fillvalue)
  
  #i <- 5
  for (i in seq(1,length(route),1)){
  
      
    if(route[i] %in% select_route) {
      slice <- array[i,]
      
      value <- mean(slice[latitude_east > low_lat & latitude_east < high_lat], na.rm = TRUE)
      sd    <- sd(slice[latitude_east > low_lat & latitude_east < high_lat], na.rm = TRUE)
      date <- ymd("2000-01-01") + date_time[i]
      
      temp <- bind_cols(date = date, var=var, value = value, sd = sd)
      
      if (exists("timeseries", inherits = FALSE)){
        timeseries <- bind_rows(timeseries, temp)
      } else{timeseries <- temp}
      
      rm(temp, value, date, sd)
      
    } 
  }
nc_close(nc)

fm_sss__ngs <- timeseries %>% 
  mutate(sss = value,
         year = year(date),
         month = month(date))

fm_sss_ngs_monthlymean <- fm_sss__ngs %>% 
  filter(month >=3 , month <=9) %>% 
  summarise(sss_mean = mean(sss, na.rm = TRUE))


rm(array,fm_sss__ngs,nc, timeseries, date_time, 
  i, latitude_east, route, slice, var)
```

The mean salinity between March and September for the NGS subregion for all years is `r round(fm_sss_ngs_monthlymean,2)`.

# Finnmaid data extraction

pCO~2~ and SST observations in NGS were extracted for all crossings.

```{r fm_ngs_all_routes}
nc <- nc_open(paste("data/Finnmaid/", "FM_all_2019_on_standard_tracks.nc", sep = ""))

# read required vectors from netcdf file
route <- ncvar_get(nc, "route")
route <- unlist(strsplit(route, ""))
date_time <- ncvar_get(nc, "time")
latitude_east <- ncvar_get(nc, "latitude_east")

for (var in c("SST_east", "pCO2_east")) {
  
  #print(var)
  
  array <- ncvar_get(nc, var) # store the data in a 2-dimensional array
  #dim(array) # should have 2 dimensions: 544 coordinate, 2089 time steps
  
  fillvalue <- ncatt_get(nc, var, "_FillValue")
  array[array == fillvalue$value] <- NA
  rm(fillvalue)
  
    for (i in seq(1,length(route),1)){
  
      
    if(route[i] %in% select_route) {
      slice <- array[i,]
      
      value <- mean(slice[latitude_east > low_lat & latitude_east < high_lat], na.rm = TRUE)
      sd    <- sd(slice[latitude_east > low_lat & latitude_east < high_lat], na.rm = TRUE)
      date <- ymd("2000-01-01") + date_time[i]
      
      fm_ngs_all_routes_part <- bind_cols(date = date, var=var, value = value, sd = sd, route=route[i])
      
      if (exists("fm_ngs_all_routes", inherits = FALSE)){
        fm_ngs_all_routes <- bind_rows(fm_ngs_all_routes, fm_ngs_all_routes_part)
      } else{fm_ngs_all_routes <- fm_ngs_all_routes_part}
      
      rm(fm_ngs_all_routes_part, value, date, sd, slice)
      
      } 
    }
  rm(array, var,i)
}   
      
nc_close(nc)

fm_ngs_all_routes %>%  
  write_csv(here::here("data/_summarized_data_files/", file = "fm_ngs_all_routes.csv"))

rm(nc, fm_ngs_all_routes, latitude_east, route,date_time)

```

# GETM windspeed

Reanalysis windspeed data as used in the GETM model run were used.

```{r read_getm_2d_mld_wind, eval=FALSE}

var_all <- c("u10", "v10")
filesList_2d <- list.files(path= "data", pattern = "Finnmaid.E.2d.20", recursive = TRUE)

file <- filesList_2d[1]
nc <- nc_open(paste("data/", file, sep = ""))

lon <- ncvar_get(nc, "lonc")
lat <- ncvar_get(nc, "latc", verbose = F)
nc_close(nc)

rm(file, nc)

for (var in var_all){

for (n in 1:length(filesList_2d)) {

file <- filesList_2d[n]

nc <- nc_open(paste("data/", file, sep = ""))

time_units <- nc$dim$time$units %>%     #we read the time unit from the netcdf file to calibrate the time 
    substr(start = 15, stop = 33) %>%   #calculation, we take the relevant information from the string
    ymd_hms()                           # and transform it to the right format

t <- time_units + ncvar_get(nc, "time")

array <- ncvar_get(nc, var) # store the data in a 2-dimensional array
dim(array) # should be 2d with dimensions: 544 coordinate, 31d*(24h/d/3h)=248 time steps

array <- as.data.frame(t(array), xy=TRUE)
array <- as_tibble(array)

gt_windspeed_ngs_part <- array %>%
  set_names(as.character(lat)) %>%
  mutate(date_time = t) %>%
  gather("lat", "value", 1:length(lat)) %>%
  mutate(lat = as.numeric(lat)) %>%
  filter(lat > low_lat, lat<high_lat) %>%
  group_by(date_time) %>%
  summarise_all("mean") %>%
  ungroup() %>%
  mutate(var = var)


if (exists("gt_windspeed_ngs")) {gt_windspeed_ngs <- bind_rows(gt_windspeed_ngs, gt_windspeed_ngs_part)
  }else {gt_windspeed_ngs <- gt_windspeed_ngs_part}

  nc_close(nc)
  rm(array, nc, t, gt_windspeed_ngs_part)
  print(n) # to see working progress
}

print(paste("gt_", var, "_ngs.csv", sep = "")) # to see working progress


rm(n, file, time_units)
}

rm(filesList_2d, var, var_all, lat, lon)


gt_windspeed_ngs <- gt_windspeed_ngs %>% 
  group_by(date_time, var) %>% 
  summarise(mean_value= mean(value)) %>% 
  pivot_wider(values_from = mean_value, names_from = var) %>% 
  mutate(U_10 = round(sqrt(u10^2 + v10^2), 3)) %>% 
  select(-c(u10, v10))

gt_windspeed_ngs %>% 
  write_csv(here::here("data/_summarized_data_files/", file = paste("gt_windspeed_ngs.csv")))

rm(gt_windspeed_ngs)

```


# C~T~ calculation

C~T~ was calculated from measured pCO~2~ based on a fixed mean alkalinity value of 1650 µmol kg-1.

```{r calculate_CT_from_pCO2_Finnmaid, eval=FALSE}

df <- read_csv(here::here("data/_summarized_data_files/", file =  "fm_ngs_all_routes.csv"))

df <- df %>%
  select(date, var, value, route) 

df <- df %>%
  drop_na() %>% 
  pivot_wider(values_from = value, names_from = var)

#calculation of CT based on pCO2 (var1) and alkalinity (var2) as input parameters
#calculation of CT in theoretical equilibrium with atmosphere (CT_equi) based on pCO2_air (var1) and alkalinity (var2) as input parameters

df <- df %>%
  rename(SST = SST_east,
         pCO2 = pCO2_east) %>% 
  drop_na() %>% 
  mutate(CT = carb(24,
                   var1=pCO2,
                   var2=1650*1e-6,
                   S=pull(fm_sss_ngs_monthlymean),
                   T=SST,
                   k1k2="m10", kf="dg", ks="d", gas="insitu")[,16]*1e6) %>% 
  mutate(year = year(date),
         pCO2_air = 400 - 2*(2015-year),
         CT_equi = carb(24,
                   var1=pCO2_air,
                   var2=1650*1e-6,
                   S=pull(fm_sss_ngs_monthlymean),
                   T=SST,
                   k1k2="m10", kf="dg", ks="d", gas="insitu")[,16]*1e6) %>% 
  select(-c(pCO2_air, year))


df %>% 
   write_csv(here::here("data/_summarized_data_files/", file = "fm_CT_ngs.csv"))

rm(df)
```

# Air-sea CO~2~ flux

The CO~2~ flux across the sea surface was calculated according to Wanninkhof (2014).


```{r calculate_gas_exchange_from_Finnmaid_pCO2_S_T_and_GETM_wind, eval=FALSE}

df_1 <- read_csv(here::here("data/_summarized_data_files/", file = "fm_CT_ngs.csv"))
df_2 <- read_csv(here::here("data/_summarized_data_files/", file = "gt_windspeed_ngs.csv"))

df_2 <- df_2 %>% 
  mutate(date = as.Date(date_time)) %>% 
  select(date, U_10) %>% 
  group_by(date) %>% 
  summarise_all("mean") %>% 
  ungroup()

df <- full_join(df_1, df_2, by = "date") %>% 
  arrange(date)

rm(df_1,df_2)

df <- df %>% 
  mutate(year = year(date),
         pCO2_int = na.approx(pCO2, na.rm = FALSE),                  #na.approx: replacing NA with interpolated values
         SST_int = na.approx(SST, na.rm = FALSE)) %>% 
  filter(!is.na(pCO2_int))

#Calculation of the Schmidt number as a funktion of temperature according to Wanninkhof (2014)
Sc_W14 <- function(tem) {
  2116.8 - 136.25 * tem + 4.7353 * tem^2 - 0.092307 * tem^3 + 0.0007555 * tem^4
}

Sc_W14(20)

# calculate flux F [mol m–2 d–1]
df <- df %>%
  mutate(pCO2_air = 400 - 2*(2015-year),
         dpCO2 = pCO2_int - pCO2_air,
         dCO2  = dpCO2 * K0(S=pull(fm_sss_ngs_monthlymean), T=SST_int),
         k     = 0.251 * U_10^2 * (Sc_W14(SST_int)/660)^(-0.5),
         flux_daily = k*dCO2*1e-5*24)


df %>% 
   write_csv(here::here("data/_merged_data_files/", file = paste("gt_fm_flux_ngs.csv")))

rm(df, Sc_W14)
```

# Time series C~T~, MLD, SST, windspeed, and air-sea fluxes

```{r visualization_CT_flux_windspeeds, fig.asp=0.5}

# read CT and flux data
gt_fm_flux_ngs <- read_csv(here::here("data/_merged_data_files/", file = "gt_fm_flux_ngs.csv"))

gt_fm_flux_ngs <- gt_fm_flux_ngs %>% 
  mutate(date = as.Date(date))

ts_xts_CT <- xts(cbind(gt_fm_flux_ngs$CT, gt_fm_flux_ngs$CT_equi), order.by = gt_fm_flux_ngs$date)
names(ts_xts_CT) <- c("CT", "CT_equi")

ts_xts_SST <- xts(gt_fm_flux_ngs$SST, order.by = gt_fm_flux_ngs$date)
names(ts_xts_SST) <- "SST"

ts_xts_windspeed <- xts(gt_fm_flux_ngs$U_10, order.by = gt_fm_flux_ngs$date)
names(ts_xts_windspeed) <- "Windspeed"

ts_xts_flux <- xts(gt_fm_flux_ngs$flux_daily, order.by = gt_fm_flux_ngs$date)
names(ts_xts_flux) <- "Daily Flux"


# read MLD data
gt_mld_fm_pco2_ngs <-
  read_csv(here::here("data/_merged_data_files/", file = "gt_mld_fm_pco2_ngs.csv"))

gt_mld_fm_pco2_ngs <- gt_mld_fm_pco2_ngs %>% 
  mutate(date = as.Date(date))

ts_xts_mld5 <- xts(gt_mld_fm_pco2_ngs$value_mld5, order.by = gt_mld_fm_pco2_ngs$date)
names(ts_xts_mld5) <- "mld_age_5"

ts_xts_CT %>% 
  dygraph(group = "Fluxes") %>% 
  dyRangeSelector(dateWindow = c("2014-01-01", "2016-12-31")) %>% 
  dySeries("CT") %>% 
  dyAxis("y", label = "CT") %>% 
  dyOptions(drawPoints = TRUE, pointSize = 1.5, connectSeparatedPoints=TRUE, strokeWidth=0.5,
            drawAxesAtZero=TRUE)

ts_xts_SST %>% 
  dygraph(group = "Fluxes") %>% 
  dyRangeSelector(dateWindow = c("2014-01-01", "2016-12-31")) %>% 
  dySeries("SST") %>% 
  dyAxis("y", label = "SST") %>% 
  dyOptions(drawPoints = TRUE, pointSize = 1.5, connectSeparatedPoints=TRUE, strokeWidth=0.5,
            drawAxesAtZero=TRUE)

ts_xts_mld5 %>% 
  dygraph(group = "Fluxes") %>% 
  dyRangeSelector(dateWindow = c("2014-01-01", "2016-12-31")) %>% 
  dySeries("mld_age_5") %>% 
  dyAxis("y", label = "mld_age_5") %>% 
  dyOptions(drawPoints = TRUE, pointSize = 1.5, connectSeparatedPoints=TRUE, strokeWidth=0.5,
            drawAxesAtZero=TRUE)

ts_xts_windspeed %>% 
  dygraph(group = "Fluxes") %>% 
  dyRangeSelector(dateWindow = c("2014-01-01", "2016-12-31")) %>% 
  dySeries("Windspeed") %>% 
  dyAxis("y", label = "Windspeed [m/s]") %>% 
  dyOptions(drawPoints = TRUE, pointSize = 1.5, connectSeparatedPoints=TRUE, strokeWidth=0.5,
            drawAxesAtZero=TRUE)

ts_xts_flux %>% 
  dygraph(group = "Fluxes") %>% 
  dyRangeSelector(dateWindow = c("2014-01-01", "2016-12-31")) %>% 
  dySeries("Daily Flux") %>% 
  dyAxis("y", label = "Daily Flux") %>% 
  dyOptions(drawPoints = TRUE, pointSize = 1.5, connectSeparatedPoints=TRUE, strokeWidth=0.5)

rm(gt_fm_flux_ngs, gt_mld_fm_pco2_ngs,
   ts_xts_CT, ts_xts_flux, ts_xts_mld5, ts_xts_SST, ts_xts_windspeed)
```

# Identify continous periods without data gaps

```{r subsetting_criteria_II}

# time

time_low <- 03 # 03 as month March
time_high <- 09 # 09 as month September

deployment_gap <- 7

```


```{r deployments}

df <- 
   read_csv(here::here("data/_summarized_data_files/", file = "fm_CT_ngs.csv"))

#generic_date <-seq(from = as.Date("2003-01-01"), to = as.Date("2019-12-31"), by = 1)

# generic_date <- as.data.frame(generic_date) %>% 
#   mutate(date = generic_date,
#          month = month(date)) %>% 
#   select(-generic_date) %>% 
#   filter(month >= time_low & month <= time_high)

df <- df %>% 
  mutate (month = month(date),
          year = year(date)) %>% 
  filter (month >= time_low & month <= time_high) %>% 
  group_by(year) %>% 
  mutate(deployment = 
           as.factor(cumsum(c(TRUE,diff(date)>= deployment_gap)))) %>% # deployment +1, when data gap > 7 days
  ungroup()

# df_NA <- full_join(generic_date, df, by = "date") %>% 
#   mutate(month = month.x) %>% 
#   select(-c(month.x, month.y))
#   
# df_NA$deployment_2 <- as.factor(df_NA$deployment)
  
#colourCount = length(unique(df_NA$deployment_2))
#getPalette = colorRampPalette(brewer.pal(9, "Set1"))

df %>% 
  ggplot(aes( x = as.Date(yday(date)), y = year, color = deployment))+
  geom_point()+
  scale_y_reverse(breaks = seq(2000,2030,1))+
  theme(axis.title.x = element_blank())
  

rm(df)

```


# Tasks / open questions

- check drop_na() before CT calculation, because thise removes quite a lot data 
  points where only SST is missing.
